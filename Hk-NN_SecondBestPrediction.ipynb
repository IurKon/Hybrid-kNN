{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt #for visualization purposes, otherwise skip this line\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data (here, file 'example_data.csv' with separator ';'); one file per supply chain phase, e.g. one file for handling, one file for preconditioning etc.\n",
    "#data should have the following columns: 'deviation reason', 'deviation measure', 'sensor role', 'absolute setpoint deviation',\n",
    "#'slope of two most recent temperature measurements', 'average setpoint deviation within one last hour',\n",
    "#'membership degree in a fuzzy set \"transportation and/or storage\" with regard to the previous physical handling point',\n",
    "#'membership degree in a fuzzy set \"transportation and/or storage\" with regard to the next physical handling point'\n",
    "\n",
    "#first two columns correspond to the target variables in two prediction settings (for deviation reason and corrective measure); others comprise predictor features\n",
    "df = pd.read_csv('example_data.csv', sep = ';')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal radius values, i.e. first cut points minimizing entropy, for deviation reason ('rr') and corrective measure ('rm')\n",
    "#(as an example, 'rr' will be used further in this code, however, replacing it with 'rm' allows for making predictions for\n",
    "#corrective measures, provided that the file 'example_data.csv' contains corrective measures is taken from 'example_data.csv' as a target variable)\n",
    "rr = rr #calculated in the course of entropy minimization procedure for deviation reasons\n",
    "rm = rm #calculated in the course of entropy minimization procedure for corrective measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe to which we will write voting results; can be used to back-engineer the voting process and understand the reasons for a specific prediction\n",
    "#colums: 'true/actual label', 'k-NN prediction', 'radius neighbor prediction', 'decision tree prediction', 'final prediction of the first round', '1-NN prediction',\n",
    "#'second major k-NN prediction', 'second major radius neighbor prediction', 'second major 1-NN prediction', 'final prediction of the second round', 'final second-best prediction', 'note' (for inspection purposes)\n",
    "rad_test_r = pd.DataFrame(columns = ('actual', 'knn', 'knn_rad', 'dt', '1nn', 'final1', 'knn2', 'knn_rad2', '1nn2', 'final2', 'finalfinal', 'note'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions for 1st and 2nd most common class and removal of the first prediction (returns a new list)\n",
    "def first(lst):\n",
    "    if len(lst) == 0:\n",
    "        result = 'first_empty'\n",
    "    else:\n",
    "        result = max(set(lst), key=lst.count)\n",
    "    return result\n",
    "def second(lst):\n",
    "    if len(lst) == 0:\n",
    "        result = 'second_empty'\n",
    "    else:\n",
    "        to_remove = max(set(lst), key=lst.count)\n",
    "        lst = [x for x in lst if x != to_remove]\n",
    "        if len(lst) == 0:\n",
    "            result = 'second_empty'\n",
    "        else:\n",
    "            result = max(set(lst), key=lst.count)\n",
    "    return result\n",
    "def removal(lst, pred):\n",
    "    lst = [x for x in lst if x != pred]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting procedure for the first round (step)\n",
    "\n",
    "#initializing classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors = n_neighbors) #n_neighbors is calculated either in CV or LOOCV procedure with the help of grid or random hyperparameter search\n",
    "dt = DecisionTreeClassifier(min_samples_leaf = n_neighbors) #min_samples_leaf corresponds to the optimal value of k neighbors to restrict overfitting of decision trees\n",
    "knnRr = RadiusNeighborsClassifier(radius = rr) #knnRm = RadiusNeighborsClassifier(radius = rm) for corrective measures\n",
    "\n",
    "#running a voting procedure with LOOCV\n",
    "for i in range(len(df)):\n",
    "    #selecting training observations and singling out a test observation\n",
    "    X = df.iloc[:, 2:]\n",
    "    y = list(df.iloc[:, 0])\n",
    "    X = X.reset_index(drop = True)\n",
    "    obs_x = list(X.iloc[i, :])\n",
    "    obs_y = y[i]\n",
    "    y_new = y\n",
    "    X_new = X.drop(X.index[i])\n",
    "    X_new = X_new.reset_index(drop = True)\n",
    "    del y_new[i]\n",
    "    \n",
    "    #fitting classifiers and making first-best predictions\n",
    "    knn.fit(X_new, y_new)\n",
    "    knnRr.fit(X_new, y_new)\n",
    "    dt.fit(X_new, y_new)\n",
    "    note = 'result: '\n",
    "    neigh = knnRr.radius_neighbors((np.array(obs_x).reshape(1, -1)))\n",
    "    neighKNN = knn.kneighbors((np.array(obs_x).reshape(1, -1)))\n",
    "    oneNN = y_new[neighKNN[1][0][0]]\n",
    "    knn_pred = knn.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    dt_pred = dt.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    dt_partitions = dt.apply(X_new)\n",
    "    dt_partition_obs = dt.apply((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    ind = []\n",
    "    list_part = list(dt_partitions)\n",
    "    for j in range(len(list_part)):\n",
    "        if list_part[j] == dt_partition_obs:\n",
    "            ind.append(j)\n",
    "    df_partition = X_new[X_new.index.isin(ind)]\n",
    "    \n",
    "    #making second-best predictions\n",
    "    #first, for k-NN\n",
    "    knn_list = [y_new[a] for a in list(neighKNN[1][0])] #list with labels of k neighbors\n",
    "    knn_list_new = removal(knn_list, knn_pred)\n",
    "    if len(knn_list_new) == 0:\n",
    "        knn_pred2 = 'null'\n",
    "    else:\n",
    "        most_common_knn = first(knn_list_new)\n",
    "        more_common_knn = second(knn_list_new)\n",
    "        if knn_list_new.count(most_common_knn) == knn_list_new.count(more_common_knn):\n",
    "            note += 'knn' + str(most_common_knn) + ' vs ' + str(more_common_knn)\n",
    "            knn_pred2 = str(most_common_knn) + ' vs ' + str(more_common_knn)\n",
    "        else:\n",
    "            knn_pred2 = most_common_knn\n",
    "    \n",
    "    #then, for radius neighbors classifier\n",
    "    if len(neigh[0][0]) == 0:\n",
    "        knnRr_pred = 'null'\n",
    "        knnRr_pred2 = 'null'\n",
    "    else:\n",
    "        knnRr_pred = knnRr.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "        knnRr_list = [y_new[a] for a in list(neigh[1][0])]\n",
    "        knnRr_list_new = removal(knnRr_list, knnRr_pred)\n",
    "        if len(knnRr_list_new) == 0:\n",
    "            knnRr_pred2 = 'null'\n",
    "        else:\n",
    "            most_common_knnRr = first(knnRr_list_new)\n",
    "            more_common_knnRr = second(knnRr_list_new)\n",
    "            if knnRr_list_new.count(most_common_knnRr) == knnRr_list_new.count(more_common_knnRr):\n",
    "                note += 'knnr' + str(most_common_knnRr) + ' vs ' + str(more_common_knnRr)\n",
    "                knnRr_pred2 = str(most_common_knnRr) + ' vs ' + str(more_common_knnRr)\n",
    "            else:\n",
    "                knnRr_pred2 = most_common_knnRr\n",
    "\n",
    "    #finally, for 1-NN classifier\n",
    "    ind_remain = [] #index of labels NOT of the magority class (knn_pred)\n",
    "    ind_list = list(neighKNN[1][0])\n",
    "    for b in range(len(ind_list)):\n",
    "        if y_new[ind_list[b]] != oneNN:\n",
    "            ind_remain.append(b)\n",
    "    ind_list_new = [ind_list[a] for a in ind_remain] #with the first majority class deleted\n",
    "    if len(ind_list_new) == 0:\n",
    "        oneNN2 = 'null'\n",
    "    else:\n",
    "        oneNN2 = y_new[ind_list_new[0]]\n",
    "        \n",
    "    #writing predictions to the created dataframe\n",
    "    if len(neigh[0][0]) != 0:\n",
    "        if knn_pred == knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final1': knn_pred, '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                           knnRr_pred2, '1nn2': oneNN2, 'note': note},\n",
    "                                           ignore_index = True)\n",
    "        elif knn_pred == dt_pred and knn_pred != knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final1': knn_pred, '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                           knnRr_pred2, '1nn2': oneNN2, 'note': note},\n",
    "                                           ignore_index = True)\n",
    "        elif knnRr_pred == dt_pred and knn_pred != knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final1': dt_pred, '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                           knnRr_pred2, '1nn2': oneNN2, 'note': note},\n",
    "                                           ignore_index = True)\n",
    "        elif knnRr_pred != knn_pred and knn_pred != dt_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final1': 'disagr', '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                           knnRr_pred2, '1nn2': oneNN2, 'note': note},\n",
    "                                           ignore_index = True)\n",
    "        else:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final1': 'missing', '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                           knnRr_pred2, '1nn2': oneNN2, 'note': note},\n",
    "                                           ignore_index = True)\n",
    "    else:\n",
    "        rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': 'null', 'dt': dt_pred,\n",
    "                                       'final1': 'null', '1nn': oneNN, 'knn2': knn_pred2, 'knn_rad2':\n",
    "                                        'null', '1nn2': oneNN2, 'note': note}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions for extracting classes from strings written to the created dataframe with prediction/voting results\n",
    "def f_class(string):\n",
    "    result = float(string[0])\n",
    "    return result\n",
    "def s_class(string):\n",
    "    if string[-1] == '0' and string[-2] == '.':\n",
    "        result = float(string[-3])\n",
    "    else:\n",
    "        result = float(string[-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different scenarios for the second best prediction (SBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of k-NN (first or second best prediciton is correct)\n",
    "knn_acc = 0\n",
    "for i in range(len(rad_test_r)):\n",
    "    if rad_test_r.iloc[i, 1] == rad_test_r.iloc[i, 0] or rad_test_r.iloc[i, 6] == rad_test_r.iloc[i, 0]:\n",
    "        knn_acc += 1\n",
    "print(knn_acc/len(rad_test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inclusive accuracy calcualtion strategy (considering avoided erroneous predictions)\n",
    "#accuracy of Hk-NN\n",
    "dfd = rad_test_r.copy()\n",
    "fin_acc = 0\n",
    "for i in range(len(dfd)):\n",
    "    act = dfd.iloc[i, 0]\n",
    "    knn1 = dfd.iloc[i, 1]\n",
    "    if dfd.iloc[i, 5] != knn1: #knn1 does NOT coincide with the prediction in the first round\n",
    "        knn2 = [dfd.iloc[i, 1]] #knn2 is assigned the value that failed in the first round, but still remains majority\n",
    "    else: #VOTED in the first round and knn1 mojority class removed\n",
    "        if type(dfd.iloc[i, 6]) != str: #digit (perfect case)\n",
    "            knn2 = [dfd.iloc[i, 6]]\n",
    "        elif dfd.iloc[i, 6] == 'null': #knn1 majority class was the only class\n",
    "            knn2 = [0] #no knn2 prediction possible\n",
    "        else: #competition\n",
    "            knn2 = [f_class(dfd.iloc[i, 6]), s_class(dfd.iloc[i, 6])] #list of values for knn2\n",
    "    if type(dfd.iloc[i, 5]) != str: #predicted value\n",
    "        if knn2 == [0]:\n",
    "            if dfd.iloc[i, 5] == act or act != knn1:\n",
    "                fin_acc += 1\n",
    "        elif len(knn2) == 1:\n",
    "            if dfd.iloc[i, 5] == act or act == knn2[0]:\n",
    "                fin_acc += 1\n",
    "        elif len(knn2) == 2:\n",
    "            if dfd.iloc[i, 5] == act or act == knn2[0] or act == knn2[1]:\n",
    "                fin_acc += 1\n",
    "        else:\n",
    "            print('something missing if final1 is not string')\n",
    "    else: #'null' or 'disagr'\n",
    "        if dfd.iloc[i, 5] == 'null' or dfd.iloc[i, 5] == 'disagr':\n",
    "            if knn2 == [0]: #both are empty or no unity\n",
    "                if act != knn1:\n",
    "                    fin_acc += 1\n",
    "            elif len(knn2) == 1: #knn2 is not empty\n",
    "                if act != knn1 or knn2[0] == act:\n",
    "                    fin_acc += 1\n",
    "            elif len(knn2) == 2: #competition in knn2\n",
    "                if act != knn1 or knn2[0] == act or knn2[1] == act:\n",
    "                    fin_acc += 1\n",
    "            else:\n",
    "                print('something missing if final1 is null or disagr')\n",
    "print(fin_acc/len(dfd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constrained accuracy calculation strategy (NOT considering avoided erroneous predictions)\n",
    "#accuracy for Hk-NN\n",
    "dfd = rad_test_r.copy()\n",
    "fin_acc = 0\n",
    "for i in range(len(dfd)):\n",
    "    act = dfd.iloc[i, 0]\n",
    "    knn1 = dfd.iloc[i, 1]\n",
    "    if dfd.iloc[i, 5] != knn1: #knn1 does NOT coincide with the prediction in the first round\n",
    "        knn2 = [dfd.iloc[i, 1]] #knn2 is assigned the value that failed in the first round, but still remains majority\n",
    "    else: #VOTED in the first round and knn1 mojority class removed\n",
    "        if type(dfd.iloc[i, 6]) != str: #digit (perfect case)\n",
    "            knn2 = [dfd.iloc[i, 6]]\n",
    "        elif dfd.iloc[i, 6] == 'null': #knn1 majority class was the only class\n",
    "            knn2 = [0] #no knn2 prediction possible\n",
    "        else: #competition\n",
    "            knn2 = [f_class(dfd.iloc[i, 6]), s_class(dfd.iloc[i, 6])] #list of values for knn2\n",
    "    if type(dfd.iloc[i, 5]) != str: #predicted value\n",
    "        if knn2 == [0]:\n",
    "            if dfd.iloc[i, 5] == act:\n",
    "                fin_acc += 1\n",
    "        elif len(knn2) == 1:\n",
    "            if dfd.iloc[i, 5] == act or act == knn2[0]:\n",
    "                fin_acc += 1\n",
    "        elif len(knn2) == 2:\n",
    "            if dfd.iloc[i, 5] == act or act == knn2[0] or act == knn2[1]:\n",
    "                fin_acc += 1\n",
    "        else:\n",
    "            print('something missing if final1 is not string')\n",
    "    else: #'null' or 'disagr'\n",
    "        if dfd.iloc[i, 5] == 'null' or dfd.iloc[i, 5] == 'disagr':\n",
    "            if knn2 == [0]: #both are empty or no unity\n",
    "                pass\n",
    "            elif len(knn2) == 1: #knn2 is not empty\n",
    "                if knn2[0] == act:\n",
    "                    fin_acc += 1\n",
    "            elif len(knn2) == 2: #competition in knn2\n",
    "                if knn2[0] == act or knn2[1] == act:\n",
    "                    fin_acc += 1\n",
    "            else:\n",
    "                print('something missing if final1 is null or disagr')\n",
    "print(fin_acc/len(dfd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
