{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt #only for visualizations, otherwise skip\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data (here, file 'example_data.csv' with separator ';'); one file per supply chain phase, e.g. one file for handling, one file for preconditioning etc.\n",
    "#data should have the following columns: 'deviation reason', 'deviation measure', 'sensor role', 'absolute setpoint deviation',\n",
    "#'slope of two most recent temperature measurements', 'average setpoint deviation within one last hour',\n",
    "#'membership degree in a fuzzy set \"transportation and/or storage\" with regard to the previous physical handling point',\n",
    "#'membership degree in a fuzzy set \"transportation and/or storage\" with regard to the next physical handling point'\n",
    "\n",
    "#first two columns correspond to the target variables in two prediction settings (for deviation reason and corrective measure); others comprise predictor features\n",
    "df = pd.read_csv('example_data.csv', sep = ';')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal radius values, i.e. first cut points minimizing entropy, for deviation reason ('rr') and corrective measure ('rm')\n",
    "#(as an example, 'rr' will be used further in this code, however, replacing it with 'rm' allows for making predictions for\n",
    "#corrective measures, provided that the file 'example_data.csv' contains corrective measures is taken from 'example_data.csv' as a target variable)\n",
    "rr = rr #calculated in the course of entropy minimization procedure for deviation reasons\n",
    "rm = rm #calculated in the course of entropy minimization procedure for corrective measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe to which we will write voting results; can be used to back-engineer the voting process and understand the reasons for a specific prediction\n",
    "#colums: 'true/actual label', 'k-NN prediction', 'radius neighbor prediction', 'decision tree prediction', 'final prediction of the first round', '1-NN prediction', 'flag for outlier status in a decision tree leaf node', 'final prediction of the second round', 'note' (for inspection purposes)\n",
    "rad_test_r = pd.DataFrame(columns = ('actual', 'knn', 'knn_rad', 'dt', 'final', '1nn', 'outlier_dt', 'final2', 'note'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the boundaries of a hypercube containing all data (for decision trees for deciding upon a flag for outlier)\n",
    "abs_min_spd = min(df['spd'])\n",
    "abs_max_spd = max(df['spd'])\n",
    "abs_min_slope = min(df['slope'])\n",
    "abs_max_slope = max(df['slope'])\n",
    "abs_min_av_spd_1h = min(df['av_spd_1h'])\n",
    "abs_max_av_spd_1h = max(df['av_spd_1h'])\n",
    "abs_min_after = min(df['m_after'])\n",
    "abs_max_after = max(df['m_after'])\n",
    "abs_min_before = min(df['m_before'])\n",
    "abs_max_before = max(df['m_before'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting procedure for the first round (step)\n",
    "\n",
    "#initializing classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors = n_neighbors) #n_neighbors is calculated either in CV or LOOCV procedure with the help of grid or random hyperparameter search\n",
    "dt = DecisionTreeClassifier(min_samples_leaf = n_neighbors) #min_samples_leaf corresponds to the optimal value of k neighbors to restrict overfitting of decision trees\n",
    "knnRr = RadiusNeighborsClassifier(radius = rr) #knnRm = RadiusNeighborsClassifier(radius = rm) for corrective measures\n",
    "\n",
    "#running a voting procedure with LOOCV\n",
    "for i in range(len(df)):\n",
    "    #selecting training observations and singling out a test observation\n",
    "    X = df.iloc[:, 2:]\n",
    "    y = list(df.iloc[:, 0])\n",
    "    X = X.reset_index(drop = True)\n",
    "    obs_x = list(X.iloc[i, :])\n",
    "    obs_y = y[i]\n",
    "    y_new = y\n",
    "    X_new = X.drop(X.index[i])\n",
    "    X_new = X_new.reset_index(drop = True)\n",
    "    del y_new[i]\n",
    "    \n",
    "    #fitting classifiers and making predictions\n",
    "    knn.fit(X_new, y_new)\n",
    "    knnRr.fit(X_new, y_new)\n",
    "    dt.fit(X_new, y_new)\n",
    "    neigh = knnRr.radius_neighbors((np.array(obs_x).reshape(1, -1)))\n",
    "    neighKNN = knn.kneighbors((np.array(obs_x).reshape(1, -1)))\n",
    "    oneNN = y_new[neighKNN[1][0][0]]\n",
    "    knn_pred = knn.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    dt_pred = dt.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    dt_partitions = dt.apply(X_new)\n",
    "    dt_partition_obs = dt.apply((np.array(obs_x)).reshape(1, -1))[0]\n",
    "    ind = []\n",
    "    list_part = list(dt_partitions)\n",
    "    for j in range(len(list_part)):\n",
    "        if list_part[j] == dt_partition_obs:\n",
    "            ind.append(j)\n",
    "    df_partition = X_new[X_new.index.isin(ind)]\n",
    "    #calculating the boundaries of a hypercube containing a leaf node of a decision tree (for deciding upon a flag for outlier)\n",
    "    min_spd = min(df_partition['spd'])\n",
    "    max_spd = max(df_partition['spd'])\n",
    "    min_slope = min(df_partition['slope'])\n",
    "    max_slope = max(df_partition['slope'])\n",
    "    min_av_spd_1h = min(df_partition['av_spd_1h'])\n",
    "    max_av_spd_1h = max(df_partition['av_spd_1h'])\n",
    "    min_after = min(df_partition['m_after'])\n",
    "    max_after = max(df_partition['m_after'])\n",
    "    min_before = min(df_partition['m_before'])\n",
    "    max_before = max(df_partition['m_before'])\n",
    "    conditions = []\n",
    "    if min_spd < obs_x[1] and abs_min_spd < obs_x[1]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "        #print(min_spd, obs_x[1])\n",
    "    if max_spd > obs_x[1] or abs_max_spd == obs_x[1]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if min_slope < obs_x[2] or abs_min_slope == obs_x[2]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if max_slope > obs_x[2] or abs_max_slope == obs_x[2]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if min_av_spd_1h < obs_x[3] or abs_min_av_spd_1h == obs_x[3]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if max_av_spd_1h > obs_x[3] or abs_max_av_spd_1h == obs_x[3]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if min_after < obs_x[4] or abs_min_after == obs_x[4]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if max_after > obs_x[4] or abs_max_after == obs_x[4]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if min_before < obs_x[5] or abs_min_before == obs_x[5]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    if max_before > obs_x[5] or abs_max_before == obs_x[5]:\n",
    "        conditions.append(0)\n",
    "    else:\n",
    "        conditions.append(1)\n",
    "    \n",
    "    if 1 in conditions:\n",
    "        final_cond = 1\n",
    "    else:\n",
    "        final_cond = 0\n",
    "    \n",
    "    #writing prediction and voting results of the first round to the created dataframe\n",
    "    if len(neigh[0][0]) != 0:\n",
    "        knnRr_pred = knnRr.predict((np.array(obs_x)).reshape(1, -1))[0]\n",
    "        if knn_pred == knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final': knn_pred, '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                           ignore_index = True)\n",
    "        elif knn_pred == dt_pred and knn_pred != knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final': knn_pred, '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                           ignore_index = True)\n",
    "        elif knnRr_pred == dt_pred and knn_pred != knnRr_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final': dt_pred, '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                           ignore_index = True)\n",
    "        elif knnRr_pred != knn_pred and knn_pred != dt_pred:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final': 'disagr', '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                           ignore_index = True)\n",
    "        else:\n",
    "            rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': knnRr_pred, 'dt': dt_pred,\n",
    "                                           'final': 'missing', '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                           ignore_index = True)\n",
    "    else:\n",
    "        rad_test_r = rad_test_r.append({'actual': obs_y, 'knn': knn_pred, 'knn_rad': 'null', 'dt': dt_pred,\n",
    "                                       'final': 'null', '1nn': oneNN, 'outlier_dt': final_cond},\n",
    "                                       ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the second round of predictions (second voting step) and writing the results to the created dataframe\n",
    "for i in range(len(rad_test_r)):\n",
    "    if rad_test_r.iloc[i, 4] == 'disagr':\n",
    "        rad_test_r.iloc[i, 7] = 'disagr'\n",
    "    elif rad_test_r.iloc[i, 4] == 'null':\n",
    "        if rad_test_r.iloc[i, 1] != rad_test_r.iloc[i, 3] and rad_test_r.iloc[i, 1] != rad_test_r.iloc[i, 5] and rad_test_r.iloc[i, 3] != rad_test_r.iloc[i, 5]:\n",
    "            rad_test_r.iloc[i, 7] = 'disagr'\n",
    "        elif rad_test_r.iloc[i, 1] == rad_test_r.iloc[i, 5] or rad_test_r.iloc[i, 5] == rad_test_r.iloc[i, 3]:\n",
    "            rad_test_r.iloc[i, 7] = rad_test_r.iloc[i, 5]\n",
    "        elif rad_test_r.iloc[i, 1] == rad_test_r.iloc[i, 3] and rad_test_r.iloc[i, 1] != rad_test_r.iloc[i, 5]:\n",
    "            rad_test_r.iloc[i, 7] = 'null'\n",
    "            rad_test_r.iloc[i, 8] = 'knn=dt!=1nn'\n",
    "    else:\n",
    "        rad_test_r.iloc[i, 7] = rad_test_r.iloc[i, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy in disagreements\n",
    "counter = 0\n",
    "for i in range(len(rad_test_r)):\n",
    "    if rad_test_r.iloc[i, 7] == 'disagr' or rad_test_r.iloc[i, 7] == 'null':\n",
    "        counter += 1\n",
    "dis_dt = 0 #decision trees\n",
    "dis_1nn = 0 #1-NN classifier\n",
    "dis_knn = 0 #k-NN classifier\n",
    "for i in range(len(rad_test_r)):\n",
    "    if rad_test_r.iloc[i, 7] == 'disagr' or rad_test_r.iloc[i, 7] == 'null':\n",
    "        if rad_test_r.iloc[i, 1] == rad_test_r.iloc[i, 0]:\n",
    "            dis_knn += 1\n",
    "        if rad_test_r.iloc[i, 3] == rad_test_r.iloc[i, 0]:\n",
    "            dis_dt += 1\n",
    "        if rad_test_r.iloc[i, 5] == rad_test_r.iloc[i, 0]:\n",
    "            dis_1nn += 1\n",
    "print('knn', dis_knn/counter)\n",
    "print('dt', dis_dt/counter)\n",
    "print('1nn', dis_1nn/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating classification accuracy and prediction coverage per algorithm, including prediction results after the first and second voting steps\n",
    "#counters for accuracy of a stand-alone algorithm\n",
    "acc_fin = 0\n",
    "acc_fin2 = 0\n",
    "acc_dt = 0\n",
    "acc_knn = 0\n",
    "acc_1nn = 0\n",
    "#counters for accuracies of Hk-NN after one and two rounds of voting\n",
    "fin_null_dis = 0\n",
    "fin2_null_dis = 0\n",
    "#extracting results form the created and completed dataframe\n",
    "for i in range(len(rad_test_r)):\n",
    "    if rad_test_r.iloc[i, 4] == 'null' or rad_test_r.iloc[i, 4] == 'disagr':\n",
    "        fin_null_dis += 1\n",
    "    if rad_test_r.iloc[i, 7] == 'null' or rad_test_r.iloc[i, 7] == 'disagr':\n",
    "        fin2_null_dis += 1\n",
    "    if rad_test_r.iloc[i, 7] == rad_test_r.iloc[i, 0]:\n",
    "        acc_fin2 += 1\n",
    "    if rad_test_r.iloc[i, 4] == rad_test_r.iloc[i, 0]:\n",
    "        acc_fin += 1\n",
    "    if rad_test_r.iloc[i, 1] == rad_test_r.iloc[i, 0]:\n",
    "        acc_knn += 1\n",
    "    if rad_test_r.iloc[i, 3] == rad_test_r.iloc[i, 0]:\n",
    "        acc_dt += 1\n",
    "    if rad_test_r.iloc[i, 5] == rad_test_r.iloc[i, 0]:\n",
    "        acc_1nn += 1\n",
    "print('knn', acc_knn/len(rad_test_r), 'covered', len(rad_test_r)/len(rad_test_r))\n",
    "print('dt', acc_dt/len(rad_test_r), 'covered', len(rad_test_r)/len(rad_test_r))\n",
    "print('1nn', acc_1nn/len(rad_test_r), 'covered', len(rad_test_r)/len(rad_test_r))\n",
    "print('fin', acc_fin/(len(rad_test_r) - fin_null_dis), 'covered', (len(rad_test_r) - fin_null_dis)/len(rad_test_r))\n",
    "print('fin2', acc_fin2/(len(rad_test_r) - fin2_null_dis), 'covered', (len(rad_test_r) - fin2_null_dis)/len(rad_test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Micro- and macro-average precision and recall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision (final, i.e. Hk-NN)\n",
    "tp_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['final2'] == 1.0)])\n",
    "tp_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['final2'] == 2.0)])\n",
    "tp_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['final2'] == 3.0)])\n",
    "tp_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['final2'] == 4.0)])\n",
    "tp_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['final2'] == 5.0)])\n",
    "tp_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & (rad_test_r['final2'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "all_fin1 = len(rad_test_r.loc[(rad_test_r['final2'] == 1.0)])\n",
    "all_fin2 = len(rad_test_r.loc[(rad_test_r['final2'] == 2.0)])\n",
    "all_fin3 = len(rad_test_r.loc[(rad_test_r['final2'] == 3.0)])\n",
    "all_fin4 = len(rad_test_r.loc[(rad_test_r['final2'] == 4.0)])\n",
    "all_fin5 = len(rad_test_r.loc[(rad_test_r['final2'] == 5.0)])\n",
    "all_fin6 = len(rad_test_r.loc[(rad_test_r['final2'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('micro precision', (tp_fin1 + tp_fin2 + tp_fin3 + tp_fin4 + tp_fin5)/(all_fin1 + all_fin2 + all_fin3 + all_fin4 + all_fin5)) #add variables for the sixth class if the number of classes is six\n",
    "print('macro precision', (tp_fin1/all_fin1 + tp_fin2/all_fin2 + tp_fin3/all_fin3 + tp_fin4/all_fin4 + tp_fin5/all_fin5)/5) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision (k-NN)\n",
    "tp_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 1.0)])\n",
    "tp_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 2.0)])\n",
    "tp_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 3.0)])\n",
    "tp_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 4.0)])\n",
    "tp_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 5.0)])\n",
    "tp_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & (rad_test_r['knn'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "all_fin1 = len(rad_test_r.loc[(rad_test_r['knn'] == 1.0)])\n",
    "all_fin2 = len(rad_test_r.loc[(rad_test_r['knn'] == 2.0)])\n",
    "all_fin3 = len(rad_test_r.loc[(rad_test_r['knn'] == 3.0)])\n",
    "all_fin4 = len(rad_test_r.loc[(rad_test_r['knn'] == 4.0)])\n",
    "all_fin5 = len(rad_test_r.loc[(rad_test_r['knn'] == 5.0)])\n",
    "all_fin6 = len(rad_test_r.loc[(rad_test_r['knn'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('micro precision', (tp_fin1 + tp_fin2 + tp_fin3 + tp_fin4 + tp_fin5)/(all_fin1 + all_fin2 + all_fin3 + all_fin4 + all_fin5)) #add variables for the sixth class if the number of classes is six\n",
    "print('macro precision', (tp_fin1/all_fin1 + tp_fin2/all_fin2 + tp_fin3/all_fin3 + tp_fin4/all_fin4 + tp_fin5/all_fin5)/5) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall (final, i.e. Hk-NN)\n",
    "tp_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['final2'] == 1.0)])\n",
    "tp_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['final2'] == 2.0)])\n",
    "tp_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['final2'] == 3.0)])\n",
    "tp_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['final2'] == 4.0)])\n",
    "tp_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['final2'] == 5.0)])\n",
    "tp_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & (rad_test_r['final2'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "act_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))])\n",
    "act_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))])\n",
    "act_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))])\n",
    "act_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))])\n",
    "act_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))])\n",
    "act_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & ((rad_test_r['final2'] != 'null') & (rad_test_r['final2'] != 'disagr'))]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('micro precision', (tp_fin1 + tp_fin2 + tp_fin3 + tp_fin4 + tp_fin5)/(act_fin1 + act_fin2 + act_fin3 + act_fin4 + act_fin5)) #add variables for the sixth class if the number of classes is six\n",
    "print('macro precision', (tp_fin1/act_fin1 + tp_fin2/act_fin2 + tp_fin3/act_fin3 + tp_fin4/act_fin4 + tp_fin5/act_fin5)/5) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall (k-NN)\n",
    "tp_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 1.0)])\n",
    "tp_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 2.0)])\n",
    "tp_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 3.0)])\n",
    "tp_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 4.0)])\n",
    "tp_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 5.0)])\n",
    "tp_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & (rad_test_r['knn'] == 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "act_fin1 = len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))])\n",
    "act_fin2 = len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))])\n",
    "act_fin3 = len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))])\n",
    "act_fin4 = len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))])\n",
    "act_fin5 = len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))])\n",
    "act_fin6 = len(rad_test_r.loc[(rad_test_r['actual'] == 6.0) & ((rad_test_r['knn'] != 'null') & (rad_test_r['knn'] != 'disagr'))]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('micro precision', (tp_fin1 + tp_fin2 + tp_fin3 + tp_fin4 + tp_fin5)/(act_fin1 + act_fin2 + act_fin3 + act_fin4 + act_fin5)) #add variables for the sixth class if the number of classes is six\n",
    "print('macro precision', (tp_fin1/act_fin1 + tp_fin2/act_fin2 + tp_fin3/act_fin3 + tp_fin4/act_fin4 + tp_fin5/act_fin5)/5) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specificity (final, i.e. Hk-NN)\n",
    "l = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "dff = rad_test_r[rad_test_r.final2.isin(l)]\n",
    "tn_fin1 = len(dff.loc[(dff['actual'] != 1.0) & (dff['final2'] != 1.0)])\n",
    "tn_fin2 = len(dff.loc[(dff['actual'] != 2.0) & (dff['final2'] != 2.0)])\n",
    "tn_fin3 = len(dff.loc[(dff['actual'] != 3.0) & (dff['final2'] != 3.0)])\n",
    "tn_fin4 = len(dff.loc[(dff['actual'] != 4.0) & (dff['final2'] != 4.0)])\n",
    "tn_fin5 = len(dff.loc[(dff['actual'] != 5.0) & (dff['final2'] != 5.0)])\n",
    "tn_fin6 = len(dff.loc[(dff['actual'] != 6.0) & (dff['final2'] != 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "fp_fin1 = len(dff.loc[(dff['final2'] == 1.0) & (dff['actual'] != 1.0)])\n",
    "fp_fin2 = len(dff.loc[(dff['final2'] == 2.0) & (dff['actual'] != 2.0)])\n",
    "fp_fin3 = len(dff.loc[(dff['final2'] == 3.0) & (dff['actual'] != 3.0)])\n",
    "fp_fin4 = len(dff.loc[(dff['final2'] == 4.0) & (dff['actual'] != 4.0)])\n",
    "fp_fin5 = len(dff.loc[(dff['final2'] == 5.0) & (dff['actual'] != 5.0)])\n",
    "fp_fin6 = len(dff.loc[(dff['final2'] == 6.0) & (dff['actual'] != 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('specificity', ((tn_fin1/(tn_fin1 + fp_fin1) + tn_fin2/(tn_fin2 + fp_fin2) + tn_fin3/(tn_fin3 + fp_fin3) + tn_fin4/(tn_fin4 + fp_fin4) + tn_fin5/(tn_fin5 + fp_fin5))/5)) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specificity (k-NN)\n",
    "l = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "dff = rad_test_r[rad_test_r.knn.isin(l)]\n",
    "tn_fin1 = len(dff.loc[(dff['actual'] != 1.0) & (dff['knn'] != 1.0)])\n",
    "tn_fin2 = len(dff.loc[(dff['actual'] != 2.0) & (dff['knn'] != 2.0)])\n",
    "tn_fin3 = len(dff.loc[(dff['actual'] != 3.0) & (dff['knn'] != 3.0)])\n",
    "tn_fin4 = len(dff.loc[(dff['actual'] != 4.0) & (dff['knn'] != 4.0)])\n",
    "tn_fin5 = len(dff.loc[(dff['actual'] != 5.0) & (dff['knn'] != 5.0)])\n",
    "tn_fin6 = len(dff.loc[(dff['actual'] != 6.0) & (dff['knn'] != 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "fp_fin1 = len(dff.loc[(dff['knn'] == 1.0) & (dff['actual'] != 1.0)])\n",
    "fp_fin2 = len(dff.loc[(dff['knn'] == 2.0) & (dff['actual'] != 2.0)])\n",
    "fp_fin3 = len(dff.loc[(dff['knn'] == 3.0) & (dff['actual'] != 3.0)])\n",
    "fp_fin4 = len(dff.loc[(dff['knn'] == 4.0) & (dff['actual'] != 4.0)])\n",
    "fp_fin5 = len(dff.loc[(dff['knn'] == 5.0) & (dff['actual'] != 5.0)])\n",
    "fp_fin6 = len(dff.loc[(dff['knn'] == 6.0) & (dff['actual'] != 6.0)]) #if there are six classes in the experimental setup, otherwise skip this line\n",
    "print('specificity', ((tn_fin1/(tn_fin1 + fp_fin1) + tn_fin2/(tn_fin2 + fp_fin2) + tn_fin3/(tn_fin3 + fp_fin3) + tn_fin4/(tn_fin4 + fp_fin4) + tn_fin5/(tn_fin5 + fp_fin5))/5)) #add variables for the sixth class and devide by six if the number of classes is six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entries for the confusion matrix (final, i.e. Hk-NN)\n",
    "#the same holds true for the sixth class\n",
    "l = ['null', 'disagr']\n",
    "dffinal = rad_test_r[~rad_test_r.final2.isin(l)]\n",
    "print('1 predicted as 1', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 1.0)]))\n",
    "print('1 predicted as 2', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 2.0)]))\n",
    "print('1 predicted as 3', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 3.0)]))\n",
    "print('1 predicted as 4', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 4.0)]))\n",
    "print('1 predicted as 5', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 5.0)]))\n",
    "print('1 predicted as 6', len(dffinal.loc[(dffinal['actual'] == 1.0) & (dffinal['final2'] == 6.0)]))\n",
    "print('2 predicted as 1', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 1.0)]))\n",
    "print('2 predicted as 2', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 2.0)]))\n",
    "print('2 predicted as 3', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 3.0)]))\n",
    "print('2 predicted as 4', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 4.0)]))\n",
    "print('2 predicted as 5', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 5.0)]))\n",
    "print('2 predicted as 6', len(dffinal.loc[(dffinal['actual'] == 2.0) & (dffinal['final2'] == 6.0)]))\n",
    "print('3 predicted as 1', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 1.0)]))\n",
    "print('3 predicted as 2', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 2.0)]))\n",
    "print('3 predicted as 3', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 3.0)]))\n",
    "print('3 predicted as 4', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 4.0)]))\n",
    "print('3 predicted as 5', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 5.0)]))\n",
    "print('3 predicted as 6', len(dffinal.loc[(dffinal['actual'] == 3.0) & (dffinal['final2'] == 6.0)]))\n",
    "print('4 predicted as 1', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 1.0)]))\n",
    "print('4 predicted as 2', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 2.0)]))\n",
    "print('4 predicted as 3', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 3.0)]))\n",
    "print('4 predicted as 4', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 4.0)]))\n",
    "print('4 predicted as 5', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 5.0)]))\n",
    "print('4 predicted as 6', len(dffinal.loc[(dffinal['actual'] == 4.0) & (dffinal['final2'] == 6.0)]))\n",
    "print('5 predicted as 1', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 1.0)]))\n",
    "print('5 predicted as 2', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 2.0)]))\n",
    "print('5 predicted as 3', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 3.0)]))\n",
    "print('5 predicted as 4', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 4.0)]))\n",
    "print('5 predicted as 5', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 5.0)]))\n",
    "print('5 predicted as 6', len(dffinal.loc[(dffinal['actual'] == 5.0) & (dffinal['final2'] == 6.0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entries for the confusion matrix (k-NN)\n",
    "#the same holds true for the sixth class\n",
    "print('1 predicted as 1', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 1.0)]))\n",
    "print('1 predicted as 2', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 2.0)]))\n",
    "print('1 predicted as 3', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 3.0)]))\n",
    "print('1 predicted as 4', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 4.0)]))\n",
    "print('1 predicted as 5', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 5.0)]))\n",
    "print('1 predicted as 6', len(rad_test_r.loc[(rad_test_r['actual'] == 1.0) & (rad_test_r['knn'] == 6.0)]))\n",
    "print('2 predicted as 1', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 1.0)]))\n",
    "print('2 predicted as 2', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 2.0)]))\n",
    "print('2 predicted as 3', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 3.0)]))\n",
    "print('2 predicted as 4', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 4.0)]))\n",
    "print('2 predicted as 5', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 5.0)]))\n",
    "print('2 predicted as 6', len(rad_test_r.loc[(rad_test_r['actual'] == 2.0) & (rad_test_r['knn'] == 6.0)]))\n",
    "print('3 predicted as 1', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 1.0)]))\n",
    "print('3 predicted as 2', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 2.0)]))\n",
    "print('3 predicted as 3', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 3.0)]))\n",
    "print('3 predicted as 4', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 4.0)]))\n",
    "print('3 predicted as 5', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 5.0)]))\n",
    "print('3 predicted as 6', len(rad_test_r.loc[(rad_test_r['actual'] == 3.0) & (rad_test_r['knn'] == 6.0)]))\n",
    "print('4 predicted as 1', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 1.0)]))\n",
    "print('4 predicted as 2', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 2.0)]))\n",
    "print('4 predicted as 3', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 3.0)]))\n",
    "print('4 predicted as 4', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 4.0)]))\n",
    "print('4 predicted as 5', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 5.0)]))\n",
    "print('4 predicted as 6', len(rad_test_r.loc[(rad_test_r['actual'] == 4.0) & (rad_test_r['knn'] == 6.0)]))\n",
    "print('5 predicted as 1', len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 1.0)]))\n",
    "print('5 predicted as 2', len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 2.0)]))\n",
    "print('5 predicted as 3', len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 3.0)]))\n",
    "print('5 predicted as 4', len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 4.0)]))\n",
    "print('5 predicted as 5', len(rad_test_r.loc[(rad_test_r['actual'] == 5.0) & (rad_test_r['knn'] == 5.0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
